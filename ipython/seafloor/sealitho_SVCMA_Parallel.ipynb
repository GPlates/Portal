{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Python multivariate analysis (Support Vector Classification) script\n",
    "# written by Simon O'Callaghan NICTA\n",
    "# 14 May 2015\n",
    "\n",
    "import matplotlib\n",
    "matplotlib.use('Agg')\n",
    "rootPath='/notebooks/'\n",
    "import sys\n",
    "sys.path.append(rootPath+'bdkd-external-devel/rocks/seafloorLitho/')\n",
    "sys.path.append(rootPath+'revrand-master/')\n",
    "sys.path.append(rootPath+'bdkd-external-devel')\n",
    "sys.path.append(\"/usr/local/lib/python3.4/site-packages/\")\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import utils\n",
    "from sklearn.svm import SVC\n",
    "from sklearn import cross_validation\n",
    "from matplotlib import pyplot as pl\n",
    "%matplotlib inline  \n",
    "from multiprocessing import Pool\n",
    "import multiprocessing\n",
    "import scipy.linalg as linalg\n",
    "\n",
    "def loadData(path):\n",
    "    data = pd.read_csv(path)\n",
    "    for i in range(len(data.columns)):\n",
    "      data  = data[np.isfinite(data[data.columns[i]])]  # Remove any nans\n",
    "\n",
    "    # Set up the features (X) and the targets or labels (y)\n",
    "    X = data[data.columns[3:]].values\n",
    "    y = data.lithology.values\n",
    "    lonlat = data[data.columns[:2]].values\n",
    "    return X-np.min(X,axis=0),y, lonlat\n",
    "\n",
    "\n",
    "def preprocessData(X):\n",
    "    X[:, 4] = np.log(X[:, 4]+1e-20)\n",
    "    X[:, 6] = np.log(X[:, 6]+1e-20)\n",
    "    return X\n",
    "\n",
    "def normaliseData(X):\n",
    "    means = np.mean(X, axis=0)\n",
    "    std_devs = np.std(X, axis=0)\n",
    "    X = (X - means)/std_devs\n",
    "    return X\n",
    "\n",
    "def printMostUsefulFeatures(X, y, nRandomFeatures, featOnListArray, resultsList,maxSampPerClass, lithoLabel):\n",
    "    results = np.asarray(resultsList).T\n",
    "    nFeatures = X.shape[1]\n",
    "    nTrueFeatures = nFeatures - nRandomFeatures\n",
    "    classifierScoreList=[]\n",
    "\n",
    "    XCull, yCull = utils.cullData(X,y,maxSampPerClass)\n",
    "    featureAccuracy = np.zeros((nTrueFeatures,results.shape[1]))\n",
    "    for nFeaturesIter in (np.arange(nTrueFeatures)+1):\n",
    "        classifierScore = np.mean(results[np.sum(featOnListArray, axis=1)==nFeaturesIter], axis=1)\n",
    "        classifierScoreList.append(np.max(classifierScore).astype(float))\n",
    "        activeFeatures = featOnListArray[np.sum(featOnListArray,axis=1)\n",
    "                                             ==nFeaturesIter,:]\n",
    "        bestFeatures = np.arange(nFeatures)[activeFeatures[np.argmax(classifierScore)]==1]+1\n",
    "        bestFeatureID = np.argmax(classifierScore)\n",
    "        featureAccuracy[(nFeaturesIter-1),:] = results[np.sum(featOnListArray, axis=1)==nFeaturesIter][bestFeatureID,:]\n",
    "        print('For a classifier using %d features,' %(nFeaturesIter))\n",
    "        print('the most informative features are:')\n",
    "        print(bestFeatures.astype(list), 'with a score of %f' %(np.max(classifierScore)))\n",
    "        scoreList = []\n",
    "        for iter in range(results.shape[1]):\n",
    "            Xrand = np.random.randn(XCull.shape[0], nFeaturesIter)\n",
    "            X_train, X_test, y_train, y_test = cross_validation.train_test_split(\n",
    "              Xrand, yCull, test_size=0.2)\n",
    "            svc = SVC(kernel='rbf', probability=True)\n",
    "            svc.fit(X_train,y_train)\n",
    "            scoreList.append(svc.score(X_test, y_test))\n",
    "\n",
    "        print('%d random features have a score of: %f' %(nFeaturesIter, np.mean(scoreList)))\n",
    "        print()\n",
    "\n",
    "    pl.figure()\n",
    "    pl.errorbar((np.arange(nTrueFeatures)+1).astype(int), np.mean(featureAccuracy,axis=1), np.std(featureAccuracy,axis=1))\n",
    "    pl.title('Area Under ROC Curve vs Number of Features')\n",
    "    pl.xlabel('Number of features')\n",
    "    pl.ylabel('AUC')\n",
    "    xint = range(0,nTrueFeatures+2)\n",
    "    pl.xticks(xint)\n",
    "    ax = pl.gca()\n",
    "    ax.set_xlim((0,nTrueFeatures+1))\n",
    "    pl.savefig('auc'+str(lithoLabel)+'.pdf')\n",
    "\n",
    "\n",
    "\n",
    "def genFeatureFreq(nFeatures, nRandomFeatures, results,featOnArray):\n",
    "    nTrueFeatures = nFeatures - nRandomFeatures\n",
    "    featureFreq = np.zeros([nTrueFeatures, nFeatures])\n",
    "\n",
    "    for scoreList in results:\n",
    "        maxFeatSortedID = np.argsort(scoreList)[::-1]\n",
    "        maxFeatSorted = featOnArray[maxFeatSortedID, :]\n",
    "\n",
    "        for nFeaturesIter in (np.arange(nTrueFeatures)+1):\n",
    "              indexBoole = np.sum(maxFeatSorted,axis=1)==nFeaturesIter\n",
    "              featureFreq[nFeaturesIter-1,:] = featureFreq[nFeaturesIter-1,:] + \\\n",
    "                                               maxFeatSorted[indexBoole,:][0,:]\n",
    "\n",
    "    return featureFreq\n",
    "\n",
    "def genAUCMatrix(nFeatures, nRandomFeatures, results,featOnArray):\n",
    "\n",
    "    results = np.mean(results,axis=0)\n",
    "\n",
    "    nTrueFeatures = nFeatures - nRandomFeatures\n",
    "    featureFreq = np.zeros([nTrueFeatures, nFeatures])\n",
    "\n",
    "    for i, activeFeats in enumerate(featOnArray[:-1,:]):\n",
    "        for j in np.arange(np.sum(activeFeats)):\n",
    "            col_id = np.where(activeFeats==1.)[0]\n",
    "            featureFreq[np.sum(activeFeats)-1,col_id[j]] = results[i]\n",
    "\n",
    "    return featureFreq\n",
    "\n",
    "\n",
    "def plotMatrix(featureFreq,lithoLabel):\n",
    "    nTrueFeatures = featureFreq.shape[0]\n",
    "    nFeatures = featureFreq.shape[1]\n",
    "    pl.figure()\n",
    "    pl.imshow(featureFreq, interpolation='nearest', extent=(0.5, nFeatures + 0.5, nTrueFeatures + 0.5, 0.5))\n",
    "    pl.xlabel('Feature ID')\n",
    "    pl.ylabel('Number of Features')\n",
    "    pl.colorbar()\n",
    "    ax = pl.gca()\n",
    "    ax.tick_params(axis='x', top='off')\n",
    "    ax.tick_params(axis='y', right='off')\n",
    "    ax.get_yaxis().set_tick_params(direction='out')\n",
    "    ax.get_xaxis().set_tick_params(direction='out')\n",
    "    pl.savefig('balancedmultvarAnalysisLabel'+str(lithoLabel)+'Seafloor.pdf')\n",
    "\n",
    "\n",
    "def removeCorrelatedFeatures(X):\n",
    "    keepdims = [0,6,4,5,7, -1]\n",
    "    X = X[:,keepdims]\n",
    "\n",
    "    return X\n",
    "\n",
    "def removeHemisphere(X, y_map, lonlat):\n",
    "    keeppoints_id= np.where(lonlat[:,1]<0)[0]\n",
    "\n",
    "    return X[keeppoints_id,:], y_map[keeppoints_id]\n",
    "\n",
    "\n",
    "def mainscript(lithoLabelList):\n",
    "\n",
    "    for lithoLabel in lithoLabelList:\n",
    "\n",
    "        # Set up Variables\n",
    "        path = rootPath+'bdkd-external-devel/rocks/seafloorLitho/seafloor_lith_data_all_features.csv'\n",
    "        nIterations = 5\n",
    "        nRandomFeatures = 1\n",
    "\n",
    "        removeLabels = [9,10,11,12]\n",
    "\n",
    "        # Load Data\n",
    "        X,y, lonlat = loadData(path)\n",
    "\n",
    "        # Remove a hemisphere from the data to analyse effects\n",
    "        X, y = removeHemisphere(X, y, lonlat)\n",
    "\n",
    "        # Preprocess the data\n",
    "        X = preprocessData(X)\n",
    "\n",
    "        # Adding random features to X\n",
    "        X = np.append(X, np.random.random([X.shape[0], nRandomFeatures]), axis=1)\n",
    "\n",
    "        # Normalise Data\n",
    "        X = normaliseData(X)\n",
    "\n",
    "        # Remove correlated features\n",
    "        X = removeCorrelatedFeatures(X)\n",
    "\n",
    "        # Map labels to groups\n",
    "        mapping = {'1': 1, '2': 1, '3': 1, '4': 2, '5': 3, '6': 4, '7': 5, '8': 5,\n",
    "                   '9': 9, '10': 10, '11': 11, '12': 12, '13': 3}\n",
    "        y_map = np.zeros(y.shape)\n",
    "        for i in range(y.shape[0]):\n",
    "            y_map[i] = mapping[str(int(y[i]))]\n",
    "\n",
    "        # Remove labels as requested by geoscientist\n",
    "        for remLab in removeLabels:\n",
    "            X = X[y_map != remLab,:]\n",
    "            y_map = y_map[y_map != remLab]\n",
    "\n",
    "        X, y_map = utils.balanceData(X, y_map)\n",
    "\n",
    "        y_map[y_map != lithoLabel] = 0\n",
    "        y_map[y_map == lithoLabel] = 1\n",
    "        nFeatures = X.shape[1]\n",
    "\n",
    "        maxSampPerClass = np.min([2000, int(np.sum(y_map))])\n",
    "\n",
    "        # Generature all permutations of the features\n",
    "        featureArray = utils.genFeatureArray(nFeatures)\n",
    "\n",
    "\n",
    "        # Set up a core pool and evaluate the performance of each permutation nIteration times\n",
    "        pool = Pool(processes=(multiprocessing.cpu_count()-1))\n",
    "        results = pool.map(utils.evalFeaturesGP, [(X,y_map,featureArray,maxSampPerClass) for i in range(nIterations)])\n",
    "\n",
    "        # Print the best performing permutations\n",
    "        printMostUsefulFeatures(X,y_map, nRandomFeatures,featureArray,results, maxSampPerClass, lithoLabel)\n",
    "\n",
    "        # Generate a matrix which shows how frequently different features were used depending on\n",
    "        # the number of features provided\n",
    "        featureFreq = genFeatureFreq(nFeatures, nRandomFeatures, results, featureArray)\n",
    "\n",
    "        np.savetxt('balancedgroup'+ str(lithoLabel)+'LithoOutput_Label.txt',\n",
    "               featureFreq)\n",
    "        plotMatrix(featureFreq/nIterations,lithoLabel)\n",
    "\n",
    "    pl.show()\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    lithoLabelList = [5]\n",
    "    mainscript(lithoLabelList)\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
